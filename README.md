# SHL Assignment: Audio Grammar Rating (Kaggle Competition)
This repository contains my solution to an SHL audio grammar rating task hosted as a Kaggle competition. The objective was to predict the grammatical quality of spoken English audio responses.

Files Included
audio-embedding-generation.ipynb – Extracts audio embeddings using Wav2Vec2.

text-extraction-from-audio.ipynb – Transcribes audio using Whisper

final-solution.ipynb – Uses audio embeddings, text embeddings and grammatical features for final prediction.

CSV files – Contain transcriptions, embeddings, and predictions (train_with_embeddings.csv, test_with_embeddings.csv, etc.).

Methodology
1. Audio Processing
Used Facebook's Wav2Vec2 model to generate audio embeddings.

Included additional audio metadata such as duration [Files with 3 min durations had distorted noises].

Trained an XGBoost model using these features to generate out-of-fold (OOF) predictions.

2. Text Extraction and Processing
Audio was transcribed using OpenAI Whisper.

Transcripts were cleaned by removing repeated sentence from the distorted audio file text.

DeBERTa was used to extract contextual text embeddings from the cleaned transcripts.

3. Feature Engineering
Explored multiple grammar-related handcrafted features like avg_parse_tree_depth, clause_count, type_token_ratio

These features were excluded from the final pipeline due to poor performance in permutation importance and partial dependence analysis.

4. Final Prediction Pipeline
Combined DeBERTa text embeddings with audio-based OOF predictions.

Trained three models: XGBoost, CatBoost, and LightGBM.

Final predictions were generated by averaging outputs from the ensemble.

# Notes on Data Leakage  
There is significant data leakage with the label distribution, which I mentioned to the organiser
